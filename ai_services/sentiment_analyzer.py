# -*- coding: utf-8 -*-
"""
Sentiment Analysis Service
===========================
ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ

ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³ Ù¾ÛŒØ§Ù…:
- positive (Ù…Ø«Ø¨Øª): 0.3 ØªØ§ 1.0
- neutral (Ø®Ù†Ø«ÛŒ): -0.3 ØªØ§ 0.3
- negative (Ù…Ù†ÙÛŒ): -1.0 ØªØ§ -0.3
"""

from typing import Dict, Optional, List
import logging
import re
from datetime import datetime

logger = logging.getLogger(__name__)

# ÙˆØ§Ú˜Ú¯Ø§Ù† Ø§Ø­Ø³Ø§Ø³ÛŒ ÙØ§Ø±Ø³ÛŒ (Sentiment Lexicon)
POSITIVE_WORDS = [
    'Ø¹Ø§Ù„ÛŒ', 'Ø®ÙˆØ¨', 'Ù…ÙˆÙÙ‚', 'Ø¨Ø±Ù†Ø¯Ù‡', 'Ø­Ù…Ø§ÛŒØª', 'Ø±Ø§ÛŒ', 'Ø¹Ø²ÛŒØ²', 'Ù…Ø­ØªØ±Ù…',
    'Ù…Ù…Ù†ÙˆÙ†', 'ØªØ´Ú©Ø±', 'Ù…ØªØ´Ú©Ø±', 'Ø®Ø³ØªÙ‡ Ù†Ø¨Ø§Ø´', 'Ø§ÙØªØ®Ø§Ø±', 'Ø¯ÙˆØ³Øª', 'Ø³Ù„Ø§Ù…',
    'Ø¯Ø±ÙˆØ¯', 'Ù…ÙˆÛŒØ¯', 'ØµØ¯ Ø¯Ø±ØµØ¯', 'Ú©Ø§Ù…Ù„', 'Ø¨Ù‡ØªØ±ÛŒÙ†', 'Ù…Ù†Ø§Ø³Ø¨', 'Ù…ÙÛŒØ¯',
    'Ø®ÙˆØ´Ø­Ø§Ù„', 'Ø±Ø§Ø¶ÛŒ', 'Ù…Ø·Ù…Ø¦Ù†', 'Ø§Ù…ÛŒØ¯ÙˆØ§Ø±', 'Ù¾ÛŒØ´Ø±ÙØª', 'Ø±Ø´Ø¯', 'Ù…ÙˆÙÙ‚ÛŒØª'
]

NEGATIVE_WORDS = [
    'Ø¨Ø¯', 'Ø¶Ø¹ÛŒÙ', 'Ø§ÙØªØ¶Ø§Ø­', 'Ø¢Ø´ØºØ§Ù„', 'Ø®Ø±Ø§Ø¨', 'Ù…Ø¹ÛŒÙˆØ¨', 'Ù…Ø´Ú©Ù„', 'Ø´Ú©Ø§ÛŒØª',
    'Ù…ØªØ§Ø³Ù', 'Ù…ØªØ§Ø³ÙØ§Ù†Ù‡', 'Ù†Ù‡', 'Ø®ÛŒØ±', 'Ø§Ø´ØªØ¨Ø§Ù‡', 'ØºÙ„Ø·', 'Ù†Ø§Ø¯Ø±Ø³Øª',
    'Ù†Ø§Ø±Ø§Ø­Øª', 'Ø¹ØµØ¨Ø§Ù†ÛŒ', 'Ù†Ø§Ø§Ù…ÛŒØ¯', 'Ù†Ú¯Ø±Ø§Ù†', 'ØªØ±Ø³', 'Ø¯Ù„Ø³Ø±Ø¯', 'Ù†Ø§Ú©Ø§Ù…'
]

INTENSIFIERS = {
    'Ø®ÛŒÙ„ÛŒ': 1.5,
    'Ø¨Ø³ÛŒØ§Ø±': 1.5,
    'Ø¨ÛŒ Ù†Ù‡Ø§ÛŒØª': 2.0,
    'ÙÙˆÙ‚ Ø§Ù„Ø¹Ø§Ø¯Ù‡': 1.8,
    'ÙˆØ§Ù‚Ø¹Ø§': 1.3,
    'Ø§ØµÙ„Ø§': 1.4,
    'Ú©Ø§Ù…Ù„Ø§': 1.5,
    'Ø¨Ù‡ Ø´Ø¯Øª': 1.6
}

NEGATIONS = ['Ù†Ù‡', 'Ù†ÛŒ', 'Ù†Ø¯Ø§Ø±Ù…', 'Ù†ÛŒØ³Øª', 'Ù†Ù…ÛŒ', 'Ù‡ÛŒÚ†', 'Ø¨Ø¯ÙˆÙ†']


class SentimentAnalyzer:
    """
    ØªØ­Ù„ÛŒÙ„â€ŒÚ¯Ø± Ø§Ø­Ø³Ø§Ø³Ø§Øª ÙØ§Ø±Ø³ÛŒ
    
    Ø§Ø² Ø¯Ùˆ Ø±ÙˆØ´ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:
    1. Lexicon-based: Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ§Ú˜Ú¯Ø§Ù† Ø§Ø­Ø³Ø§Ø³ÛŒ
    2. ML-based: Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ deep learning (Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡)
    """
    
    def __init__(self, use_ml: bool = False):
        """
        Args:
            use_ml: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ ML (ÙØ¹Ù„Ø§Ù‹ False)
        """
        self.use_ml = use_ml
        self.ml_model = None
        
        if use_ml:
            try:
                self._load_ml_model()
            except Exception as e:
                logger.warning(f"Could not load sentiment ML model: {e}")
                self.use_ml = False
    
    def _load_ml_model(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ML"""
        try:
            from transformers import pipeline
            
            # Ù…Ø¯Ù„ sentiment analysis ÙØ§Ø±Ø³ÛŒ
            # Ù…Ø«Ø§Ù„: HooshvareLab/bert-fa-base-uncased-sentiment
            self.ml_model = pipeline(
                "sentiment-analysis",
                model="HooshvareLab/bert-fa-base-uncased-sentiment",
                device=-1
            )
            logger.info("Sentiment ML model loaded successfully")
        except Exception as e:
            logger.error(f"Error loading sentiment model: {e}")
            raise
    
    def analyze(self, text: str) -> Dict:
        """
        ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³ Ù…ØªÙ†
        
        Args:
            text: Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ
        
        Returns:
            dict Ø´Ø§Ù…Ù„:
                - score: Ù†Ù…Ø±Ù‡ (-1 ØªØ§ 1)
                - label: positive, neutral, negative
                - confidence: Ø§Ø·Ù…ÛŒÙ†Ø§Ù† (0-1)
                - emotions: Ø§Ø­Ø³Ø§Ø³Ø§Øª ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡
        """
        if not text or not text.strip():
            return self._create_result(0.0, 'neutral', 0.0, 'empty')
        
        # ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù† Ù…ØªÙ†
        text = self._clean_text(text)
        
        # ØªÙ„Ø§Ø´ Ø¨Ø§ ML
        if self.use_ml and self.ml_model:
            try:
                result = self._analyze_ml(text)
                if result['confidence'] > 0.6:
                    return result
            except Exception as e:
                logger.error(f"ML sentiment analysis failed: {e}")
        
        # fallback Ø¨Ù‡ lexicon-based
        return self._analyze_lexicon(text)
    
    def _analyze_ml(self, text: str) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ ML"""
        result = self.ml_model(text)[0]
        
        # ØªØ¨Ø¯ÛŒÙ„ label Ø¨Ù‡ score
        label = result['label'].lower()
        if 'positive' in label or 'pos' in label:
            score = 0.7
            label = 'positive'
        elif 'negative' in label or 'neg' in label:
            score = -0.7
            label = 'negative'
        else:
            score = 0.0
            label = 'neutral'
        
        confidence = result['score']
        
        return self._create_result(score, label, confidence, 'ml')
    
    def _analyze_lexicon(self, text: str) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ§Ú˜Ú¯Ø§Ù†"""
        words = text.split()
        
        positive_count = 0
        negative_count = 0
        intensity_factor = 1.0
        has_negation = False
        
        for i, word in enumerate(words):
            # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙÛŒ
            if any(neg in word for neg in NEGATIONS):
                has_negation = True
                continue
            
            # Ø¨Ø±Ø±Ø³ÛŒ ØªØ´Ø¯ÛŒØ¯
            for intensifier, factor in INTENSIFIERS.items():
                if intensifier in word:
                    intensity_factor = factor
                    break
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ù…Ø§Øª Ù…Ø«Ø¨Øª
            if any(pos in word for pos in POSITIVE_WORDS):
                if has_negation:
                    negative_count += intensity_factor
                    has_negation = False
                else:
                    positive_count += intensity_factor
                intensity_factor = 1.0
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ù…Ø§Øª Ù…Ù†ÙÛŒ
            elif any(neg in word for neg in NEGATIVE_WORDS):
                if has_negation:
                    positive_count += intensity_factor
                    has_negation = False
                else:
                    negative_count += intensity_factor
                intensity_factor = 1.0
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ù…Ø±Ù‡
        total = positive_count + negative_count
        if total == 0:
            score = 0.0
            label = 'neutral'
            confidence = 0.3
        else:
            score = (positive_count - negative_count) / total
            
            if score > 0.3:
                label = 'positive'
            elif score < -0.3:
                label = 'negative'
            else:
                label = 'neutral'
            
            confidence = min(abs(score) + 0.3, 1.0)
        
        return self._create_result(score, label, confidence, 'lexicon')
    
    def _create_result(self, score: float, label: str, confidence: float, method: str) -> Dict:
        """Ø³Ø§Ø®Øª Ù†ØªÛŒØ¬Ù‡ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯"""
        label_fa = {
            'positive': 'Ù…Ø«Ø¨Øª',
            'neutral': 'Ø®Ù†Ø«ÛŒ',
            'negative': 'Ù…Ù†ÙÛŒ'
        }
        
        # Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª
        emotions = self._detect_emotions(score, label)
        
        return {
            'score': round(score, 2),
            'label': label,
            'label_fa': label_fa.get(label, 'Ù†Ø§Ù…Ø´Ø®Øµ'),
            'confidence': round(confidence, 2),
            'emotions': emotions,
            'method': method,
            'timestamp': datetime.now().isoformat()
        }
    
    def _detect_emotions(self, score: float, label: str) -> List[str]:
        """Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±"""
        emotions = []
        
        if label == 'positive':
            if score > 0.7:
                emotions.append('Ø¨Ø³ÛŒØ§Ø± Ø®ÙˆØ´Ø­Ø§Ù„')
            elif score > 0.5:
                emotions.append('Ø®ÙˆØ´Ø­Ø§Ù„')
            else:
                emotions.append('Ø±Ø§Ø¶ÛŒ')
        
        elif label == 'negative':
            if score < -0.7:
                emotions.append('Ø¨Ø³ÛŒØ§Ø± Ù†Ø§Ø±Ø§Ø­Øª')
            elif score < -0.5:
                emotions.append('Ù†Ø§Ø±Ø§Ø­Øª')
            else:
                emotions.append('Ù†Ú¯Ø±Ø§Ù†')
        
        else:
            emotions.append('Ø®Ù†Ø«ÛŒ')
        
        return emotions
    
    def _clean_text(self, text: str) -> str:
        """ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù† Ù…ØªÙ†"""
        text = re.sub(r'[\r\n\t]+', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ hazm
        try:
            from hazm import Normalizer
            normalizer = Normalizer()
            text = normalizer.normalize(text)
        except ImportError:
            pass
        
        return text
    
    def batch_analyze(self, texts: List[str]) -> List[Dict]:
        """ØªØ­Ù„ÛŒÙ„ Ø¯Ø³ØªÙ‡â€ŒØ¬Ù…Ø¹ÛŒ"""
        return [self.analyze(text) for text in texts]
    
    def get_sentiment_trend(self, results: List[Dict]) -> Dict:
        """Ø±ÙˆÙ†Ø¯ Ø§Ø­Ø³Ø§Ø³Ø§Øª"""
        if not results:
            return {}
        
        positive_count = sum(1 for r in results if r['label'] == 'positive')
        neutral_count = sum(1 for r in results if r['label'] == 'neutral')
        negative_count = sum(1 for r in results if r['label'] == 'negative')
        
        total = len(results)
        avg_score = sum(r['score'] for r in results) / total
        
        return {
            'total': total,
            'positive': positive_count,
            'neutral': neutral_count,
            'negative': negative_count,
            'positive_percent': round(positive_count / total * 100, 1),
            'neutral_percent': round(neutral_count / total * 100, 1),
            'negative_percent': round(negative_count / total * 100, 1),
            'avg_score': round(avg_score, 2),
            'overall': 'positive' if avg_score > 0.2 else 'negative' if avg_score < -0.2 else 'neutral'
        }


# Singleton instance
_analyzer_instance = None

def get_sentiment_analyzer(use_ml: bool = False) -> SentimentAnalyzer:
    """Ø¯Ø±ÛŒØ§ÙØª instance Ø³Ø±Ø§Ø³Ø±ÛŒ"""
    global _analyzer_instance
    if _analyzer_instance is None:
        _analyzer_instance = SentimentAnalyzer(use_ml=use_ml)
    return _analyzer_instance


# ØªØ³Øª
if __name__ == "__main__":
    analyzer = SentimentAnalyzer(use_ml=False)
    
    test_messages = [
        "Ø´Ù…Ø§ ÙˆØ§Ù‚Ø¹Ø§ Ø¹Ø§Ù„ÛŒ Ù‡Ø³ØªÛŒØ¯! Ø®ÛŒÙ„ÛŒ Ù…ÙˆÙÙ‚ Ø¨Ø§Ø´ÛŒØ¯ ğŸ‘",
        "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø¨Ø§ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§ Ù…ÙˆØ§ÙÙ‚ Ù†ÛŒØ³ØªÙ…",
        "Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØªÙˆÙ† Ø±Ùˆ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯ÛŒØ¯ Ù„Ø·ÙØ§",
        "Ø®ÛŒÙ„ÛŒ Ø¨Ø¯ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ØŒ Ø§ØµÙ„Ø§ Ø±Ø§Ø¶ÛŒ Ù†ÛŒØ³ØªÙ…",
        "Ù…Ù…Ù†ÙˆÙ† Ø§Ø² Ø²Ø­Ù…Ø§ØªØªÙˆÙ†ØŒ Ø§Ù…ÛŒØ¯ÙˆØ§Ø±Ù… Ù…ÙˆÙÙ‚ Ø¨Ø´ÛŒØ¯"
    ]
    
    print("ğŸ§ª ØªØ³Øª ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª:\n")
    for msg in test_messages:
        result = analyzer.analyze(msg)
        print(f"ğŸ“ Ù¾ÛŒØ§Ù…: {msg}")
        print(f"   ğŸ˜Š Ø§Ø­Ø³Ø§Ø³: {result['label_fa']} ({result['label']})")
        print(f"   ğŸ“Š Ù†Ù…Ø±Ù‡: {result['score']}")
        print(f"   ğŸ’¯ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {result['confidence']*100:.0f}%")
        print(f"   â¤ï¸  Ø§Ø­Ø³Ø§Ø³Ø§Øª: {', '.join(result['emotions'])}")
        print(f"   ğŸ”§ Ø±ÙˆØ´: {result['method']}\n")
    
    # ØªØ³Øª Ø±ÙˆÙ†Ø¯
    results = [analyzer.analyze(msg) for msg in test_messages]
    trend = analyzer.get_sentiment_trend(results)
    print("ğŸ“ˆ Ø±ÙˆÙ†Ø¯ Ú©Ù„ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª:")
    print(f"   Ù…Ø«Ø¨Øª: {trend['positive_percent']}%")
    print(f"   Ø®Ù†Ø«ÛŒ: {trend['neutral_percent']}%")
    print(f"   Ù…Ù†ÙÛŒ: {trend['negative_percent']}%")
    print(f"   Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†: {trend['avg_score']}")
    print(f"   Ù†ØªÛŒØ¬Ù‡: {trend['overall']}")
