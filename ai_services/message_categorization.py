# -*- coding: utf-8 -*-
"""
Message Categorization Service
===============================
Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ

Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§:
- complaint (Ø´Ú©Ø§ÛŒØª): Ú¯Ù„Ù‡â€ŒÙ…Ù†Ø¯ÛŒ Ø§Ø² Ù…Ø´Ú©Ù„Ø§Øª Ø´Ù‡Ø±ÛŒ
- suggestion (Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯): Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø³Ø§Ø²Ù†Ø¯Ù‡  
- question (Ø³ÙˆØ§Ù„): Ø³ÙˆØ§Ù„Ø§Øª Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§
- support (Ø­Ù…Ø§ÛŒØª): Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø­Ù…Ø§ÛŒØªÛŒ Ùˆ ØªØ´ÙˆÛŒÙ‚ÛŒ
- criticism (Ø§Ù†ØªÙ‚Ø§Ø¯): Ø§Ù†ØªÙ‚Ø§Ø¯Ø§Øª Ø³Ø§Ø²Ù†Ø¯Ù‡
"""

from typing import Dict, Optional, List
import logging
from datetime import datetime
import re

# Ø¨Ø±Ø§ÛŒ Ø­Ø§Ù„Øª fallback Ø§Ú¯Ø± Ù…Ø¯Ù„ ML Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¨ÙˆØ¯
KEYWORD_PATTERNS = {
    'complaint': [
        r'Ù…Ø´Ú©Ù„', r'Ø´Ú©Ø§ÛŒØª', r'Ú†Ø±Ø§', r'Ù†Ù…ÛŒ\s*Ø´ÙˆØ¯', r'Ù†Ø´Ø¯Ù‡', r'Ù†Ú©Ø±Ø¯Ù‡',
        r'Ø¨Ø¯', r'Ø¶Ø¹ÛŒÙ', r'Ø§ÙØªØ¶Ø§Ø­', r'Ø¢Ø´ØºØ§Ù„', r'Ø®Ø±Ø§Ø¨', r'Ù…Ø¹ÛŒÙˆØ¨',
        r'Ú¯Ø±ÙˆÙ†ÛŒ', r'Ø¨ÛŒÚ©Ø§Ø±ÛŒ', r'Ø¢Ù„ÙˆØ¯Ú¯ÛŒ', r'ØªØ±Ø§ÙÛŒÚ©', r'Ú†Ø§Ù„Ù‡', r'Ø®ÛŒØ§Ø¨ÙˆÙ†'
    ],
    'suggestion': [
        r'Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯', r'Ø¨Ù‡ØªØ±', r'Ù…ÛŒ\s*ØªÙˆÙ†ÛŒØ¯', r'Ù…ÛŒ\s*Ø´ÙˆØ¯', r'Ø§Ú¯Ø±', r'Ø¨Ø¯ Ù†ÛŒØ³Øª',
        r'Ø®ÙˆØ¨\s+Ø§Ø³Øª', r'Ù„Ø§Ø²Ù…', r'Ø¶Ø±ÙˆØ±ÛŒ', r'Ø¨Ø§ÛŒØ¯', r'Ø¨Ø§ÛŒØ³ØªÛŒ', r'Ù…ÛŒ\s*ØªÙˆØ§Ù†'
    ],
    'question': [
        r'\?', r'Ú†Ø±Ø§', r'Ú©ÛŒ', r'Ú†Ú¯ÙˆÙ†Ù‡', r'Ú†Ø·ÙˆØ±', r'Ø¢ÛŒØ§', r'Ú†Ù‡\s+Ø²Ù…Ø§Ù†ÛŒ',
        r'Ø¨Ø±Ù†Ø§Ù…Ù‡', r'Ù‚ØµØ¯', r'Ù…ÛŒ\s*Ø®ÙˆØ§Ù‡ÛŒØ¯', r'Ù…ÛŒ\s*Ø®ÙˆØ§ÛŒØ¯', r'Ø³ÙˆØ§Ù„'
    ],
    'support': [
        r'Ø¹Ø§Ù„ÛŒ', r'Ù…ÙˆÙÙ‚', r'Ø¨Ø±Ù†Ø¯Ù‡', r'Ø­Ù…Ø§ÛŒØª', r'Ø±Ø§ÛŒ', r'Ù…ÛŒ\s*Ø¯Ù‡Ù…', r'Ù…ÛŒ\s*Ø¯Ù…',
        r'Ø¹Ø²ÛŒØ²', r'Ø¯ÙˆØ³Øª', r'Ù…Ø­ØªØ±Ù…', r'Ø¢Ù‚Ø§ÛŒ', r'Ø®Ø§Ù†Ù…', r'Ø¯Ø±ÙˆØ¯', r'Ø³Ù„Ø§Ù…',
        r'Ù…Ù…Ù†ÙˆÙ†', r'ØªØ´Ú©Ø±', r'Ù…ØªØ´Ú©Ø±', r'Ø®Ø³ØªÙ‡\s+Ù†Ø¨Ø§Ø´', r'Ø§ÙØªØ®Ø§Ø±'
    ],
    'criticism': [
        r'Ø§Ù†ØªÙ‚Ø§Ø¯', r'Ù†Ù‚Ø¯', r'Ø§Ù…Ø§', r'ÙˆÙ„ÛŒ', r'Ù…ØªØ§Ø³Ù', r'Ù…ØªØ§Ø³ÙØ§Ù†Ù‡',
        r'Ù†Ù‡', r'Ø®ÛŒØ±', r'Ù…ÙˆØ§ÙÙ‚ Ù†ÛŒØ³Øª', r'Ø§Ø´ØªØ¨Ø§Ù‡', r'ØºÙ„Ø·', r'Ù†Ø§Ø¯Ø±Ø³Øª'
    ]
}

CATEGORY_NAMES_FA = {
    'complaint': 'Ø´Ú©Ø§ÛŒØª',
    'suggestion': 'Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯',
    'question': 'Ø³ÙˆØ§Ù„',
    'support': 'Ø­Ù…Ø§ÛŒØª',
    'criticism': 'Ø§Ù†ØªÙ‚Ø§Ø¯',
    'unknown': 'Ù†Ø§Ù…Ø´Ø®Øµ'
}

PRIORITY_MAP = {
    'complaint': 'high',      # Ø´Ú©Ø§ÛŒØª Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§
    'question': 'high',       # Ø³ÙˆØ§Ù„ Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§
    'criticism': 'medium',    # Ø§Ù†ØªÙ‚Ø§Ø¯ Ø§ÙˆÙ„ÙˆÛŒØª Ù…ØªÙˆØ³Ø·
    'suggestion': 'medium',   # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø§ÙˆÙ„ÙˆÛŒØª Ù…ØªÙˆØ³Ø·
    'support': 'low',         # Ø­Ù…Ø§ÛŒØª Ø§ÙˆÙ„ÙˆÛŒØª Ù¾Ø§ÛŒÛŒÙ†
    'unknown': 'low'
}

logger = logging.getLogger(__name__)


class MessageCategorizer:
    """
    Ú©Ù„Ø§Ø³ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
    
    Ø§Ø² Ø¯Ùˆ Ø±ÙˆØ´ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:
    1. ML-based: Ù…Ø¯Ù„ ParsBERT Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ù‚ÛŒÙ‚
    2. Rule-based: Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ Ø¨Ø±Ø§ÛŒ fallback
    """
    
    def __init__(self, use_ml: bool = True):
        """
        Args:
            use_ml: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ ML ÛŒØ§ ÙÙ‚Ø· rule-based
        """
        self.use_ml = use_ml
        self.ml_model = None
        
        if use_ml:
            try:
                self._load_ml_model()
            except Exception as e:
                logger.warning(f"Could not load ML model, falling back to rule-based: {e}")
                self.use_ml = False
    
    def _load_ml_model(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ML"""
        try:
            from transformers import pipeline
            
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ ÙØ§Ø±Ø³ÛŒ
            # Ø¯Ø± Ø­Ø§Ù„Øª ÙˆØ§Ù‚Ø¹ÛŒØŒ Ø¨Ø§ÛŒØ¯ Ù…Ø¯Ù„ fine-tune Ø´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯
            self.ml_model = pipeline(
                "text-classification",
                model="HooshvareLab/bert-fa-base-uncased",
                device=-1  # CPU (-1), GPU (0)
            )
            logger.info("ML model loaded successfully")
        except ImportError:
            logger.error("transformers not installed, install with: pip install transformers torch")
            raise
        except Exception as e:
            logger.error(f"Error loading ML model: {e}")
            raise
    
    def categorize(self, text: str) -> Dict:
        """
        Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù¾ÛŒØ§Ù…
        
        Args:
            text: Ù…ØªÙ† Ù¾ÛŒØ§Ù… ÙØ§Ø±Ø³ÛŒ
        
        Returns:
            dict Ø´Ø§Ù…Ù„:
                - category: Ø¯Ø³ØªÙ‡ (complaint, suggestion, ...)
                - category_fa: Ù†Ø§Ù… ÙØ§Ø±Ø³ÛŒ Ø¯Ø³ØªÙ‡
                - confidence: Ø§Ø·Ù…ÛŒÙ†Ø§Ù† (0-1)
                - priority: Ø§ÙˆÙ„ÙˆÛŒØª (high, medium, low)
                - method: Ø±ÙˆØ´ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ (ml, rule_based)
        """
        if not text or not text.strip():
            return self._create_result('unknown', 0.0, 'empty')
        
        # ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù† Ù…ØªÙ†
        text = self._clean_text(text)
        
        # ØªÙ„Ø§Ø´ Ø¨Ø§ ML
        if self.use_ml and self.ml_model:
            try:
                result = self._categorize_ml(text)
                if result['confidence'] > 0.5:  # threshold
                    return result
            except Exception as e:
                logger.error(f"ML categorization failed: {e}")
        
        # fallback Ø¨Ù‡ rule-based
        return self._categorize_rule_based(text)
    
    def _categorize_ml(self, text: str) -> Dict:
        """Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ ML"""
        # Ø¯Ø± Ø­Ø§Ù„Øª ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§ÛŒØ¯ Ù…Ø¯Ù„ fine-tune Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ù‡
        # Ø§ÛŒÙ† ÙÙ‚Ø· ÛŒÚ© Ù…Ø«Ø§Ù„ Ø§Ø³Øª
        result = self.ml_model(text)[0]
        
        # map Ú©Ø±Ø¯Ù† label Ø¨Ù‡ category
        category = self._map_label_to_category(result['label'])
        confidence = result['score']
        
        return self._create_result(category, confidence, 'ml')
    
    def _categorize_rule_based(self, text: str) -> Dict:
        """Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡"""
        scores = {cat: 0 for cat in KEYWORD_PATTERNS.keys()}
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ù‡Ø± Ø¯Ø³ØªÙ‡
        for category, patterns in KEYWORD_PATTERNS.items():
            for pattern in patterns:
                matches = len(re.findall(pattern, text, re.IGNORECASE))
                scores[category] += matches
        
        # Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø³ØªÙ‡ Ø¨Ø§ Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø²
        if max(scores.values()) == 0:
            return self._create_result('unknown', 0.0, 'rule_based')
        
        best_category = max(scores, key=scores.get)
        total_matches = sum(scores.values())
        confidence = scores[best_category] / total_matches if total_matches > 0 else 0.0
        
        return self._create_result(best_category, confidence, 'rule_based')
    
    def _create_result(self, category: str, confidence: float, method: str) -> Dict:
        """Ø³Ø§Ø®Øª Ù†ØªÛŒØ¬Ù‡ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯"""
        return {
            'category': category,
            'category_fa': CATEGORY_NAMES_FA.get(category, 'Ù†Ø§Ù…Ø´Ø®Øµ'),
            'confidence': round(confidence, 2),
            'priority': PRIORITY_MAP.get(category, 'low'),
            'method': method,
            'timestamp': datetime.now().isoformat()
        }
    
    def _clean_text(self, text: str) -> str:
        """ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù† Ùˆ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†"""
        # Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
        text = re.sub(r'[\r\n\t]+', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ hazm (Ø§Ú¯Ø± Ù†ØµØ¨ Ø¨Ø§Ø´Ø¯)
        try:
            from hazm import Normalizer
            normalizer = Normalizer()
            text = normalizer.normalize(text)
        except ImportError:
            pass
        
        return text
    
    def _map_label_to_category(self, label: str) -> str:
        """ØªØ¨Ø¯ÛŒÙ„ label Ù…Ø¯Ù„ Ø¨Ù‡ category"""
        # mapping Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¯Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡
        # Ø§ÛŒÙ† Ø¨Ø§ÛŒØ¯ customize Ø¨Ø´Ù‡
        label_lower = label.lower()
        
        if 'complaint' in label_lower or 'negative' in label_lower:
            return 'complaint'
        elif 'suggestion' in label_lower or 'proposal' in label_lower:
            return 'suggestion'
        elif 'question' in label_lower or 'query' in label_lower:
            return 'question'
        elif 'support' in label_lower or 'positive' in label_lower:
            return 'support'
        elif 'criticism' in label_lower or 'critique' in label_lower:
            return 'criticism'
        else:
            return 'unknown'
    
    def batch_categorize(self, texts: List[str]) -> List[Dict]:
        """Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¬Ù…Ø¹ÛŒ"""
        return [self.categorize(text) for text in texts]
    
    def get_statistics(self, results: List[Dict]) -> Dict:
        """Ø¢Ù…Ø§Ø± Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ"""
        if not results:
            return {}
        
        stats = {
            'total': len(results),
            'by_category': {},
            'by_priority': {},
            'avg_confidence': 0.0,
            'method_usage': {}
        }
        
        for result in results:
            # by category
            cat = result['category']
            stats['by_category'][cat] = stats['by_category'].get(cat, 0) + 1
            
            # by priority
            priority = result['priority']
            stats['by_priority'][priority] = stats['by_priority'].get(priority, 0) + 1
            
            # method
            method = result['method']
            stats['method_usage'][method] = stats['method_usage'].get(method, 0) + 1
            
            # confidence
            stats['avg_confidence'] += result['confidence']
        
        stats['avg_confidence'] /= len(results)
        stats['avg_confidence'] = round(stats['avg_confidence'], 2)
        
        return stats


# Instance Ø³Ø±Ø§Ø³Ø±ÛŒ (singleton pattern)
_categorizer_instance = None

def get_categorizer(use_ml: bool = True) -> MessageCategorizer:
    """Ø¯Ø±ÛŒØ§ÙØª instance Ø³Ø±Ø§Ø³Ø±ÛŒ"""
    global _categorizer_instance
    if _categorizer_instance is None:
        _categorizer_instance = MessageCategorizer(use_ml=use_ml)
    return _categorizer_instance


# ØªØ³Øª Ø³Ø±ÛŒØ¹
if __name__ == "__main__":
    # ØªØ³Øª Ø¨Ø§ rule-based (Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ ML)
    categorizer = MessageCategorizer(use_ml=False)
    
    test_messages = [
        "Ø³Ù„Ø§Ù…ØŒ Ú†Ø±Ø§ Ø®ÛŒØ§Ø¨ÙˆÙ† Ù…Ø­Ù„Ù‡ Ù…Ø§ Ø¢Ø³ÙØ§Ù„Øª Ù†Ø´Ø¯Ù‡ØŸ",
        "Ø´Ù…Ø§ Ø¹Ø§Ù„ÛŒ Ù‡Ø³ØªÛŒØ¯ØŒ Ù…ÙˆÙÙ‚ Ø¨Ø§Ø´ÛŒØ¯",
        "Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ù… ÛŒÚ© Ù¾Ø§Ø±Ú© Ø¯Ø± Ù…Ø­Ù„Ù‡ Ø¨Ø³Ø§Ø²ÛŒØ¯",
        "Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ ØªØ±Ø§ÙÛŒÚ© Ú†ÛŒÙ‡ØŸ",
        "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø¨Ø§ Ø³ÛŒØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§ Ù…ÙˆØ§ÙÙ‚ Ù†ÛŒØ³ØªÙ…"
    ]
    
    print("ğŸ§ª ØªØ³Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§:\n")
    for msg in test_messages:
        result = categorizer.categorize(msg)
        print(f"ğŸ“ Ù¾ÛŒØ§Ù…: {msg}")
        print(f"   ğŸ·ï¸  Ø¯Ø³ØªÙ‡: {result['category_fa']} ({result['category']})")
        print(f"   ğŸ“Š Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {result['confidence']*100:.0f}%")
        print(f"   âš¡ Ø§ÙˆÙ„ÙˆÛŒØª: {result['priority']}")
        print(f"   ğŸ”§ Ø±ÙˆØ´: {result['method']}\n")
